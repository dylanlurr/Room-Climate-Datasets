{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e7740c",
   "metadata": {},
   "source": [
    "# Model 1 - Room Climate Prediction\n",
    "\n",
    "## EDA dan Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b95f87",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed22076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719703a7",
   "metadata": {},
   "source": [
    "### 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f337db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names based on the CSV structure\n",
    "column_names = ['<EID>', '<AbsT>', '<RelT>', '<NID>', '<Temp>', '<RelH>', '<L1>', '<L2>', \n",
    "                '<Occ>', '<Act>', '<Door>', '<Win>']\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('datasets-location_A/room_climate-location_A-measurement38.csv', \n",
    "                 names=column_names, header=None)\n",
    "\n",
    "print(\"Dataset berhasil dimuat!\")\n",
    "print(f\"Ukuran dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ce4b33",
   "metadata": {},
   "source": [
    "### 3. Inspeksi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d84a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampilkan 5 baris pertama\n",
    "print(\"=\" * 80)\n",
    "print(\"HEAD - 5 Baris Pertama:\")\n",
    "print(\"=\" * 80)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0914fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tampilkan info dataset\n",
    "print(\"=\" * 80)\n",
    "print(\"INFO - Informasi Dataset:\")\n",
    "print(\"=\" * 80)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1923d0af",
   "metadata": {},
   "source": [
    "### 4. Filter Sensor (Node) A1\n",
    "\n",
    "Pilih hanya data dari sensor A1 untuk dijadikan fokus model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb91423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek unique nodes yang tersedia\n",
    "print(\"Node yang tersedia dalam dataset:\")\n",
    "print(df['<NID>'].unique())\n",
    "print(f\"\\nJumlah data per node:\")\n",
    "print(df['<NID>'].value_counts().sort_index())\n",
    "\n",
    "# Filter data untuk sensor A1 (node = 1)\n",
    "df_a1 = df[df['<NID>'] == 1].copy()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Data setelah filter untuk Node A1 (Node = 1):\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Ukuran dataset A1: {df_a1.shape}\")\n",
    "print(f\"\\nSample data A1:\")\n",
    "df_a1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eadaaa0",
   "metadata": {},
   "source": [
    "### 5. Pilih Fitur (X) - Input Features\n",
    "\n",
    "Pilih kolom-kolom yang akan dijadikan fitur input: `<Temp>`, `<RelH>`, `<L1>`, dan `<L2>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb39af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pilih kolom fitur (X)\n",
    "feature_columns = ['<Temp>', '<RelH>', '<L1>', '<L2>']\n",
    "X = df_a1[feature_columns].copy()\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Fitur Input (X):\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Shape: {X.shape}\")\n",
    "print(f\"Kolom: {list(X.columns)}\")\n",
    "print(f\"\\nSample data X:\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf490fbb",
   "metadata": {},
   "source": [
    "### 6. Buat Label (y) - Target Variable\n",
    "\n",
    "Buat target variable dengan menggeser kolom `<Temp>` satu langkah ke belakang (shift(-1)). Ini akan mengambil suhu dari baris berikutnya sebagai target prediksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c59c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat target variable (y) dengan shift(-1)\n",
    "# Ini akan mengambil suhu dari baris berikutnya sebagai target\n",
    "y = df_a1['<Temp>'].shift(-1)\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Target Variable (y):\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Shape: {y.shape}\")\n",
    "print(f\"\\nSample data y (5 baris pertama):\")\n",
    "print(y.head())\n",
    "print(f\"\\nCek nilai NaN di y:\")\n",
    "print(f\"Jumlah NaN: {y.isna().sum()}\")\n",
    "print(f\"Posisi NaN: {y[y.isna()].index.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c52eee",
   "metadata": {},
   "source": [
    "### 7. Bersihkan Data\n",
    "\n",
    "Karena `shift(-1)` menghasilkan satu nilai NaN di baris terakhir, kita perlu menghapus baris tersebut dari X dan y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3eccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus baris terakhir yang mengandung NaN\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Sebelum pembersihan:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# Bersihkan data dengan menghapus baris terakhir\n",
    "X = X.iloc[:-1]\n",
    "y = y.iloc[:-1]\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Setelah pembersihan:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nCek NaN di y setelah pembersihan: {y.isna().sum()}\")\n",
    "print(f\"Cek NaN di X setelah pembersihan: {X.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebcb762",
   "metadata": {},
   "source": [
    "### 8. Statistik Deskriptif dan Visualisasi\n",
    "\n",
    "Mari kita lihat statistik deskriptif dari data yang telah dibersihkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591977db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik deskriptif untuk fitur\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Statistik Deskriptif Fitur (X):\")\n",
    "print(f\"{'='*80}\")\n",
    "print(X.describe())\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Statistik Deskriptif Target (y):\")\n",
    "print(f\"{'='*80}\")\n",
    "print(y.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi korelasi antar fitur\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = X.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Korelasi Antar Fitur (Sensor A1)', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMatriks Korelasi:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1a0d97",
   "metadata": {},
   "source": [
    "### 9. Ringkasan Preprocessing\n",
    "\n",
    "Data telah siap untuk digunakan dalam model machine learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RINGKASAN PREPROCESSING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n1. Dataset Awal:\")\n",
    "print(f\"   - File: room_climate-location_A-measurement38.csv\")\n",
    "print(f\"   - Total baris: {df.shape[0]}\")\n",
    "print(f\"   - Total kolom: {df.shape[1]}\")\n",
    "\n",
    "print(f\"\\n2. Filter Sensor:\")\n",
    "print(f\"   - Sensor dipilih: A1 (Node = 1)\")\n",
    "print(f\"   - Jumlah data sensor A1: {df_a1.shape[0]}\")\n",
    "\n",
    "print(f\"\\n3. Fitur (X):\")\n",
    "print(f\"   - Kolom: {list(X.columns)}\")\n",
    "print(f\"   - Shape: {X.shape}\")\n",
    "\n",
    "print(f\"\\n4. Target (y):\")\n",
    "print(f\"   - Target: Suhu (Temp) pada timestep berikutnya\")\n",
    "print(f\"   - Shape: {y.shape}\")\n",
    "\n",
    "print(f\"\\n5. Data Bersih:\")\n",
    "print(f\"   - Total sampel: {X.shape[0]}\")\n",
    "print(f\"   - Tidak ada nilai NaN\")\n",
    "print(f\"   - Data siap untuk training model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff6024",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Splitting dan Scaling\n",
    "\n",
    "### 10. Split Dataset untuk Training dan Validation\n",
    "\n",
    "**Strategi Splitting:**\n",
    "- **Training Set (80%)** + **Validation Set (20%)**: Dari `measurement38.csv`\n",
    "- **Test Set (100%)**: Dari `measurement39.csv` (file terpisah)\n",
    "\n",
    "Keuntungan pendekatan ini:\n",
    "1. ‚úÖ Test set benar-benar independen dari training\n",
    "2. ‚úÖ Menghindari data leakage\n",
    "3. ‚úÖ Evaluasi model lebih objektif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06bc983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data dari measurement38.csv menjadi 80% training dan 20% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% untuk validation\n",
    "    random_state=42,    # untuk reproducibility\n",
    "    shuffle=False       # False karena ini time series data\n",
    ")\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"SPLIT DATA DARI MEASUREMENT38.CSV:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  - X_train shape: {X_train.shape}\")\n",
    "print(f\"  - y_train shape: {y_train.shape}\")\n",
    "print(f\"  - Persentase: {(len(X_train) / len(X)) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\nValidation Set:\")\n",
    "print(f\"  - X_val shape: {X_val.shape}\")\n",
    "print(f\"  - y_val shape: {y_val.shape}\")\n",
    "print(f\"  - Persentase: {(len(X_val) / len(X)) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Total data dari measurement38.csv: {len(X)} samples\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc82ffe",
   "metadata": {},
   "source": [
    "### 11. Load dan Preprocess Test Set (measurement39.csv)\n",
    "\n",
    "Load dataset testing dari file terpisah dan terapkan preprocessing yang sama seperti training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ecc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset dari measurement39.csv\n",
    "df_test = pd.read_csv('datasets-location_A/room_climate-location_A-measurement39.csv', \n",
    "                      names=column_names, header=None)\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"LOAD TEST DATASET (MEASUREMENT39.CSV):\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Shape: {df_test.shape}\")\n",
    "print(f\"\\nSample data:\")\n",
    "print(df_test.head())\n",
    "\n",
    "# Filter untuk sensor A1 (Node = 1)\n",
    "df_test_a1 = df_test[df_test['<NID>'] == 1].copy()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Filter untuk Node A1:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Shape setelah filter: {df_test_a1.shape}\")\n",
    "\n",
    "# Ekstrak fitur dan target untuk test set (PREPROCESSING SAMA SEPERTI TRAINING)\n",
    "X_test = df_test_a1[feature_columns].copy()\n",
    "y_test = df_test_a1['<Temp>'].shift(-1)\n",
    "\n",
    "# Bersihkan NaN di baris terakhir\n",
    "X_test = X_test.iloc[:-1]\n",
    "y_test = y_test.iloc[:-1]\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"TEST SET (dari measurement39.csv):\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  - X_test shape: {X_test.shape}\")\n",
    "print(f\"  - y_test shape: {y_test.shape}\")\n",
    "print(f\"  - Tidak ada NaN: {X_test.isna().sum().sum() == 0 and y_test.isna().sum() == 0}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e2a9f",
   "metadata": {},
   "source": [
    "### 12. Feature Scaling dengan StandardScaler\n",
    "\n",
    "**Penting untuk Deep Learning!** Scaling membantu model konvergen lebih cepat dan stabil.\n",
    "\n",
    "**Catatan Penting:**\n",
    "- Fit scaler **HANYA** pada training set\n",
    "- Transform training, validation, dan test set menggunakan scaler yang sama\n",
    "- Ini mencegah **data leakage** dari validation/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb00d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize scaler untuk fitur (X) dan target (y)\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# FIT scaler HANYA pada training set\n",
    "scaler_X.fit(X_train)\n",
    "scaler_y.fit(y_train.values.reshape(-1, 1))\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"FEATURE SCALING PARAMETERS (dari Training Set):\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nScaler X (Features):\")\n",
    "print(f\"  Mean: {scaler_X.mean_}\")\n",
    "print(f\"  Std:  {scaler_X.scale_}\")\n",
    "\n",
    "print(f\"\\nScaler y (Target):\")\n",
    "print(f\"  Mean: {scaler_y.mean_[0]:.4f}\")\n",
    "print(f\"  Std:  {scaler_y.scale_[0]:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8563e21e",
   "metadata": {},
   "source": [
    "### 13. Transform Semua Dataset dengan Scaler\n",
    "\n",
    "Terapkan scaling ke training, validation, dan test set menggunakan parameter dari training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b949fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform fitur (X) untuk semua set\n",
    "X_train_scaled = scaler_X.transform(X_train)\n",
    "X_val_scaled = scaler_X.transform(X_val)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# Transform target (y) untuk semua set\n",
    "y_train_scaled = scaler_y.transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_val_scaled = scaler_y.transform(y_val.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"DATA SETELAH SCALING:\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\n1Ô∏è‚É£  TRAINING SET (80% dari measurement38.csv)\")\n",
    "print(f\"   ‚îú‚îÄ X_train_scaled shape: {X_train_scaled.shape}\")\n",
    "print(f\"   ‚îú‚îÄ y_train_scaled shape: {y_train_scaled.shape}\")\n",
    "print(f\"   ‚îú‚îÄ X_train_scaled mean: {X_train_scaled.mean(axis=0)}\")\n",
    "print(f\"   ‚îî‚îÄ X_train_scaled std:  {X_train_scaled.std(axis=0)}\")\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£  VALIDATION SET (20% dari measurement38.csv)\")\n",
    "print(f\"   ‚îú‚îÄ X_val_scaled shape: {X_val_scaled.shape}\")\n",
    "print(f\"   ‚îî‚îÄ y_val_scaled shape: {y_val_scaled.shape}\")\n",
    "\n",
    "print(f\"\\n3Ô∏è‚É£  TEST SET (100% dari measurement39.csv)\")\n",
    "print(f\"   ‚îú‚îÄ X_test_scaled shape: {X_test_scaled.shape}\")\n",
    "print(f\"   ‚îî‚îÄ y_test_scaled shape: {y_test_scaled.shape}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ Semua data telah di-scale dan siap untuk model Deep Learning!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263df69b",
   "metadata": {},
   "source": [
    "### 14. Visualisasi Perbandingan Data Sebelum dan Sesudah Scaling\n",
    "\n",
    "Mari kita lihat efek scaling pada distribusi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51fe2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi perbandingan sebelum dan sesudah scaling\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "fig.suptitle('Perbandingan Distribusi Data: Sebelum vs Sesudah Scaling', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "feature_names = ['<Temp>', '<RelH>', '<L1>', '<L2>']\n",
    "\n",
    "# Baris pertama: Sebelum Scaling\n",
    "for i, feature in enumerate(feature_names):\n",
    "    axes[0, i].hist(X_train[feature], bins=30, edgecolor='black', \n",
    "                    alpha=0.7, color='lightcoral')\n",
    "    axes[0, i].set_title(f'{feature} - Sebelum Scaling', fontweight='bold')\n",
    "    axes[0, i].set_xlabel('Nilai')\n",
    "    axes[0, i].set_ylabel('Frekuensi')\n",
    "    axes[0, i].grid(True, alpha=0.3)\n",
    "\n",
    "# Baris kedua: Sesudah Scaling\n",
    "for i in range(4):\n",
    "    axes[1, i].hist(X_train_scaled[:, i], bins=30, edgecolor='black', \n",
    "                    alpha=0.7, color='lightgreen')\n",
    "    axes[1, i].set_title(f'{feature_names[i]} - Sesudah Scaling', fontweight='bold')\n",
    "    axes[1, i].set_xlabel('Nilai (Scaled)')\n",
    "    axes[1, i].set_ylabel('Frekuensi')\n",
    "    axes[1, i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Tampilkan mean dan std\n",
    "    mean_val = X_train_scaled[:, i].mean()\n",
    "    std_val = X_train_scaled[:, i].std()\n",
    "    axes[1, i].axvline(mean_val, color='red', linestyle='--', linewidth=2, \n",
    "                       label=f'Œº={mean_val:.2f}')\n",
    "    axes[1, i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Perhatikan bahwa data yang sudah di-scale memiliki mean ‚âà 0 dan std ‚âà 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03e06a1",
   "metadata": {},
   "source": [
    "### 15. Ringkasan Final: Data Siap untuk Deep Learning Model\n",
    "\n",
    "Semua preprocessing, splitting, dan scaling telah selesai!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee61ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üéØ RINGKASAN FINAL - DATA PREPROCESSING & SPLITTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìÅ SUMBER DATA:\")\n",
    "print(f\"   ‚îú‚îÄ Training + Validation: measurement38.csv (Node A1)\")\n",
    "print(f\"   ‚îî‚îÄ Testing: measurement39.csv (Node A1)\")\n",
    "\n",
    "print(f\"\\nüìä PEMBAGIAN DATASET:\")\n",
    "print(f\"\\n   1Ô∏è‚É£  TRAINING SET (80% dari measurement38.csv)\")\n",
    "print(f\"      ‚îú‚îÄ X_train_scaled: {X_train_scaled.shape} ‚Üí {X_train_scaled.nbytes / 1024:.2f} KB\")\n",
    "print(f\"      ‚îú‚îÄ y_train_scaled: {y_train_scaled.shape} ‚Üí {y_train_scaled.nbytes / 1024:.2f} KB\")\n",
    "print(f\"      ‚îî‚îÄ Total samples: {len(X_train_scaled):,}\")\n",
    "\n",
    "print(f\"\\n   2Ô∏è‚É£  VALIDATION SET (20% dari measurement38.csv)\")\n",
    "print(f\"      ‚îú‚îÄ X_val_scaled: {X_val_scaled.shape} ‚Üí {X_val_scaled.nbytes / 1024:.2f} KB\")\n",
    "print(f\"      ‚îú‚îÄ y_val_scaled: {y_val_scaled.shape} ‚Üí {y_val_scaled.nbytes / 1024:.2f} KB\")\n",
    "print(f\"      ‚îî‚îÄ Total samples: {len(X_val_scaled):,}\")\n",
    "\n",
    "print(f\"\\n   3Ô∏è‚É£  TEST SET (100% dari measurement39.csv)\")\n",
    "print(f\"      ‚îú‚îÄ X_test_scaled: {X_test_scaled.shape} ‚Üí {X_test_scaled.nbytes / 1024:.2f} KB\")\n",
    "print(f\"      ‚îú‚îÄ y_test_scaled: {y_test_scaled.shape} ‚Üí {y_test_scaled.nbytes / 1024:.2f} KB\")\n",
    "print(f\"      ‚îî‚îÄ Total samples: {len(X_test_scaled):,}\")\n",
    "\n",
    "print(f\"\\nüîß FITUR (INPUT):\")\n",
    "print(f\"   {feature_columns}\")\n",
    "\n",
    "print(f\"\\nüéØ TARGET (OUTPUT):\")\n",
    "print(f\"   Suhu (<Temp>) pada timestep berikutnya\")\n",
    "\n",
    "print(f\"\\nüìè SCALING:\")\n",
    "print(f\"   ‚îú‚îÄ Method: StandardScaler (mean=0, std=1)\")\n",
    "print(f\"   ‚îú‚îÄ Fitted on: Training set only\")\n",
    "print(f\"   ‚îî‚îÄ Applied to: Train, Validation, Test\")\n",
    "\n",
    "print(f\"\\n‚úÖ STATUS:\")\n",
    "print(f\"   ‚îú‚îÄ Preprocessing: ‚úì Selesai\")\n",
    "print(f\"   ‚îú‚îÄ Data Splitting: ‚úì Selesai\")\n",
    "print(f\"   ‚îú‚îÄ Feature Scaling: ‚úì Selesai\")\n",
    "print(f\"   ‚îú‚îÄ No Missing Values: ‚úì Confirmed\")\n",
    "print(f\"   ‚îî‚îÄ Ready for Deep Learning: ‚úì YES\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ Data siap untuk digunakan dalam model Deep Learning!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1526fc60",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Building - LSTM Architecture\n",
    "\n",
    "### 16. Import TensorFlow/Keras Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e351352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    print(f\"GPU Devices: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c896aa",
   "metadata": {},
   "source": [
    "### 17. Prepare Data for LSTM - Create Sequences dengan Sliding Window\n",
    "\n",
    "LSTM membutuhkan input 3D: `(samples, timesteps, features)`\n",
    "\n",
    "Kita akan menggunakan **sliding window approach** untuk membuat sequences dari data time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e880b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, window_size):\n",
    "    \"\"\"\n",
    "    Create sequences untuk LSTM menggunakan sliding window.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Input features (numpy array)\n",
    "    - y: Target values (numpy array)\n",
    "    - window_size: Jumlah timesteps yang digunakan untuk prediksi\n",
    "    \n",
    "    Returns:\n",
    "    - X_seq: Sequences dengan shape (samples, window_size, features)\n",
    "    - y_seq: Target values dengan shape (samples,)\n",
    "    \"\"\"\n",
    "    X_seq, y_seq = [], []\n",
    "    \n",
    "    for i in range(len(X) - window_size):\n",
    "        # Ambil window_size timesteps sebagai input\n",
    "        X_seq.append(X[i:i + window_size])\n",
    "        # Target adalah nilai setelah window\n",
    "        y_seq.append(y[i + window_size])\n",
    "    \n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Set window size (jumlah timesteps yang digunakan untuk prediksi)\n",
    "WINDOW_SIZE = 20  # Gunakan 20 timesteps sebelumnya untuk prediksi\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"MEMBUAT SEQUENCES UNTUK LSTM\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nWindow Size: {WINDOW_SIZE} timesteps\")\n",
    "print(f\"\\nSetiap sample akan menggunakan {WINDOW_SIZE} timesteps sebelumnya\")\n",
    "print(f\"untuk memprediksi suhu di timestep berikutnya.\")\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20250e04",
   "metadata": {},
   "source": [
    "### 18. Apply Sliding Window ke Training, Validation, dan Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22d69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences untuk training set\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, WINDOW_SIZE)\n",
    "\n",
    "# Create sequences untuk validation set\n",
    "X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val_scaled, WINDOW_SIZE)\n",
    "\n",
    "# Create sequences untuk test set\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, WINDOW_SIZE)\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"SHAPES SETELAH SEQUENCE CREATION:\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\nüìä TRAINING SET:\")\n",
    "print(f\"   X_train_seq shape: {X_train_seq.shape} ‚Üí (samples, timesteps, features)\")\n",
    "print(f\"   y_train_seq shape: {y_train_seq.shape}\")\n",
    "print(f\"   Samples: {len(X_train_seq):,}\")\n",
    "\n",
    "print(f\"\\nüìä VALIDATION SET:\")\n",
    "print(f\"   X_val_seq shape: {X_val_seq.shape}\")\n",
    "print(f\"   y_val_seq shape: {y_val_seq.shape}\")\n",
    "print(f\"   Samples: {len(X_val_seq):,}\")\n",
    "\n",
    "print(f\"\\nüìä TEST SET:\")\n",
    "print(f\"   X_test_seq shape: {X_test_seq.shape}\")\n",
    "print(f\"   y_test_seq shape: {y_test_seq.shape}\")\n",
    "print(f\"   Samples: {len(X_test_seq):,}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ Data siap untuk LSTM Model!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f7ece",
   "metadata": {},
   "source": [
    "### 19. Build LSTM Model - Medium Complexity\n",
    "\n",
    "**Arsitektur:**\n",
    "- LSTM Layer 1: 64 units, return_sequences=True\n",
    "- LSTM Layer 2: 32 units\n",
    "- Dense Layer: 16 units (ReLU)\n",
    "- Output Layer: 1 unit (Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19506f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any previous models\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Build LSTM Model\n",
    "model = models.Sequential([\n",
    "    # Input Layer (implisit, tidak perlu didefinisikan)\n",
    "    \n",
    "    # LSTM Layer 1: 64 units\n",
    "    layers.LSTM(\n",
    "        units=64,\n",
    "        return_sequences=True,  # Return sequences untuk LSTM layer berikutnya\n",
    "        input_shape=(WINDOW_SIZE, X_train_seq.shape[2]),  # (timesteps, features)\n",
    "        name='lstm_layer_1'\n",
    "    ),\n",
    "    layers.Dropout(0.2, name='dropout_1'),\n",
    "    \n",
    "    # LSTM Layer 2: 32 units\n",
    "    layers.LSTM(\n",
    "        units=32,\n",
    "        return_sequences=False,  # Tidak return sequences karena ini layer terakhir\n",
    "        name='lstm_layer_2'\n",
    "    ),\n",
    "    layers.Dropout(0.2, name='dropout_2'),\n",
    "    \n",
    "    # Dense Hidden Layer: 16 units\n",
    "    layers.Dense(\n",
    "        units=16,\n",
    "        activation='relu',\n",
    "        name='dense_hidden'\n",
    "    ),\n",
    "    \n",
    "    # Output Layer: 1 unit (temperature prediction)\n",
    "    layers.Dense(\n",
    "        units=1,\n",
    "        activation='linear',  # Linear untuk regression\n",
    "        name='output_layer'\n",
    "    )\n",
    "])\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"üß† LSTM MODEL ARCHITECTURE\")\n",
    "print(f\"{'='*80}\")\n",
    "model.summary()\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9816d86",
   "metadata": {},
   "source": [
    "### 20. Compile Model dengan MAE dan RMSE Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4275cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom RMSE metric\n",
    "def rmse(y_true, y_pred):\n",
    "    return keras.backend.sqrt(keras.backend.mean(keras.backend.square(y_pred - y_true)))\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mse',  # Mean Squared Error sebagai loss function\n",
    "    metrics=[\n",
    "        'mae',   # Mean Absolute Error\n",
    "        rmse     # Root Mean Squared Error (custom)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"‚úÖ MODEL COMPILED\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nüìã Configuration:\")\n",
    "print(f\"   Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"   Loss Function: MSE (Mean Squared Error)\")\n",
    "print(f\"   Metrics: MAE, RMSE\")\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8a778d",
   "metadata": {},
   "source": [
    "### 21. Setup Callbacks untuk Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da94a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup callbacks\n",
    "callbacks = [\n",
    "    # Early Stopping: Stop training jika tidak ada improvement\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        mode='min'\n",
    "    ),\n",
    "    \n",
    "    # Model Checkpoint: Save model terbaik\n",
    "    ModelCheckpoint(\n",
    "        filepath='best_lstm_model.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        mode='min'\n",
    "    ),\n",
    "    \n",
    "    # Reduce Learning Rate: Kurangi learning rate jika stuck\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1,\n",
    "        mode='min'\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"‚úÖ CALLBACKS CONFIGURED\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\n1Ô∏è‚É£  EarlyStopping:\")\n",
    "print(f\"   - Monitor: val_loss\")\n",
    "print(f\"   - Patience: 15 epochs\")\n",
    "print(f\"   - Restore best weights: True\")\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£  ModelCheckpoint:\")\n",
    "print(f\"   - Save to: best_lstm_model.keras\")\n",
    "print(f\"   - Save best only: True\")\n",
    "\n",
    "print(f\"\\n3Ô∏è‚É£  ReduceLROnPlateau:\")\n",
    "print(f\"   - Monitor: val_loss\")\n",
    "print(f\"   - Factor: 0.5 (reduce by half)\")\n",
    "print(f\"   - Patience: 5 epochs\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97660d",
   "metadata": {},
   "source": [
    "### 22. Train Model\n",
    "\n",
    "Mulai training dengan data yang telah diproses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53617f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"üöÄ STARTING TRAINING\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nüìã Training Configuration:\")\n",
    "print(f\"   Epochs: {EPOCHS}\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Training Samples: {len(X_train_seq):,}\")\n",
    "print(f\"   Validation Samples: {len(X_val_seq):,}\")\n",
    "print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ TRAINING COMPLETED!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd1b7c6",
   "metadata": {},
   "source": [
    "### 23. Visualisasi Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "fig.suptitle('Training History - LSTM Model', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Loss\n",
    "axes[0].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_title('Model Loss (MSE)', fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: MAE\n",
    "axes[1].plot(history.history['mae'], label='Training MAE', linewidth=2)\n",
    "axes[1].plot(history.history['val_mae'], label='Validation MAE', linewidth=2)\n",
    "axes[1].set_title('Mean Absolute Error (MAE)', fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: RMSE\n",
    "axes[2].plot(history.history['rmse'], label='Training RMSE', linewidth=2)\n",
    "axes[2].plot(history.history['val_rmse'], label='Validation RMSE', linewidth=2)\n",
    "axes[2].set_title('Root Mean Squared Error (RMSE)', fontweight='bold')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('RMSE')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üìä FINAL TRAINING METRICS:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nTraining:\")\n",
    "print(f\"   Loss (MSE): {history.history['loss'][-1]:.6f}\")\n",
    "print(f\"   MAE: {history.history['mae'][-1]:.6f}\")\n",
    "print(f\"   RMSE: {history.history['rmse'][-1]:.6f}\")\n",
    "\n",
    "print(f\"\\nValidation:\")\n",
    "print(f\"   Loss (MSE): {history.history['val_loss'][-1]:.6f}\")\n",
    "print(f\"   MAE: {history.history['val_mae'][-1]:.6f}\")\n",
    "print(f\"   RMSE: {history.history['val_rmse'][-1]:.6f}\")\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb4bb6b",
   "metadata": {},
   "source": [
    "### 24. Evaluasi Model pada Test Set\n",
    "\n",
    "Evaluasi performa model pada test set yang independen (measurement39.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfae3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_results = model.evaluate(X_test_seq, y_test_seq, verbose=0)\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"üéØ TEST SET EVALUATION (measurement39.csv)\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nTest Samples: {len(X_test_seq):,}\")\n",
    "print(f\"\\nüìä Test Metrics:\")\n",
    "print(f\"   Loss (MSE): {test_results[0]:.6f}\")\n",
    "print(f\"   MAE: {test_results[1]:.6f}\")\n",
    "print(f\"   RMSE: {test_results[2]:.6f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_scaled = model.predict(X_test_seq, verbose=0)\n",
    "\n",
    "# Inverse transform untuk mendapatkan nilai asli (dalam derajat Celsius)\n",
    "y_test_original = scaler_y.inverse_transform(y_test_seq.reshape(-1, 1)).flatten()\n",
    "y_pred_original = scaler_y.inverse_transform(y_pred_scaled).flatten()\n",
    "\n",
    "# Calculate metrics pada skala asli\n",
    "mae_original = mean_absolute_error(y_test_original, y_pred_original)\n",
    "rmse_original = math.sqrt(mean_squared_error(y_test_original, y_pred_original))\n",
    "\n",
    "print(f\"\\nüìä Test Metrics (Skala Asli - ¬∞C):\")\n",
    "print(f\"   MAE: {mae_original:.4f} ¬∞C\")\n",
    "print(f\"   RMSE: {rmse_original:.4f} ¬∞C\")\n",
    "\n",
    "print(f\"\\nüí° Interpretasi:\")\n",
    "print(f\"   Model memiliki rata-rata error {mae_original:.4f}¬∞C dalam memprediksi suhu.\")\n",
    "print(f\"   RMSE menunjukkan error {rmse_original:.4f}¬∞C dengan sensitifitas terhadap outlier.\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e8e85",
   "metadata": {},
   "source": [
    "### 25. Visualisasi Prediksi vs Aktual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d708ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi hasil prediksi\n",
    "fig, axes = plt.subplots(2, 1, figsize=(18, 10))\n",
    "fig.suptitle('LSTM Model - Prediksi vs Aktual (Test Set)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Time Series - Prediksi vs Aktual\n",
    "axes[0].plot(y_test_original, label='Actual Temperature', linewidth=2, alpha=0.7)\n",
    "axes[0].plot(y_pred_original, label='Predicted Temperature', linewidth=2, alpha=0.7)\n",
    "axes[0].set_title('Temperature Prediction Over Time', fontweight='bold', fontsize=14)\n",
    "axes[0].set_xlabel('Sample Index')\n",
    "axes[0].set_ylabel('Temperature (¬∞C)')\n",
    "axes[0].legend(fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add error band\n",
    "error = np.abs(y_test_original - y_pred_original)\n",
    "axes[0].fill_between(range(len(y_test_original)), \n",
    "                      y_pred_original - error, \n",
    "                      y_pred_original + error, \n",
    "                      alpha=0.2, color='red', label='Error Band')\n",
    "\n",
    "# Plot 2: Scatter Plot - Prediksi vs Aktual\n",
    "axes[1].scatter(y_test_original, y_pred_original, alpha=0.5, s=20)\n",
    "axes[1].plot([y_test_original.min(), y_test_original.max()], \n",
    "             [y_test_original.min(), y_test_original.max()], \n",
    "             'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[1].set_title('Predicted vs Actual Temperature (Scatter)', fontweight='bold', fontsize=14)\n",
    "axes[1].set_xlabel('Actual Temperature (¬∞C)')\n",
    "axes[1].set_ylabel('Predicted Temperature (¬∞C)')\n",
    "axes[1].legend(fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add R¬≤ score\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test_original, y_pred_original)\n",
    "axes[1].text(0.05, 0.95, f'R¬≤ = {r2:.4f}', \n",
    "             transform=axes[1].transAxes, \n",
    "             fontsize=14, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üìä ADDITIONAL METRICS:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"   R¬≤ Score: {r2:.4f}\")\n",
    "print(f\"   Min Error: {error.min():.4f} ¬∞C\")\n",
    "print(f\"   Max Error: {error.max():.4f} ¬∞C\")\n",
    "print(f\"   Mean Error: {error.mean():.4f} ¬∞C\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a2310",
   "metadata": {},
   "source": [
    "### 26. Ringkasan Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0ad405",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üéØ LSTM MODEL - FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìÅ DATA:\")\n",
    "print(f\"   Training Data: measurement38.csv (Node A1)\")\n",
    "print(f\"   Test Data: measurement39.csv (Node A1)\")\n",
    "print(f\"   Window Size: {WINDOW_SIZE} timesteps\")\n",
    "\n",
    "print(\"\\nüß† ARSITEKTUR MODEL:\")\n",
    "print(f\"   Type: LSTM (Long Short-Term Memory)\")\n",
    "print(f\"   Complexity: Medium\")\n",
    "print(f\"   Layers:\")\n",
    "print(f\"      ‚îî‚îÄ LSTM Layer 1: 64 units\")\n",
    "print(f\"      ‚îî‚îÄ LSTM Layer 2: 32 units\")\n",
    "print(f\"      ‚îî‚îÄ Dense Layer: 16 units (ReLU)\")\n",
    "print(f\"      ‚îî‚îÄ Output Layer: 1 unit (Linear)\")\n",
    "print(f\"   Total Parameters: {model.count_params():,}\")\n",
    "\n",
    "print(\"\\nüîß TRAINING CONFIGURATION:\")\n",
    "print(f\"   Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"   Loss Function: MSE\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Epochs: {len(history.history['loss'])}\")\n",
    "print(f\"   Callbacks: EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\")\n",
    "\n",
    "print(\"\\nüìä PERFORMANCE METRICS:\")\n",
    "print(f\"   Test MAE: {mae_original:.4f} ¬∞C\")\n",
    "print(f\"   Test RMSE: {rmse_original:.4f} ¬∞C\")\n",
    "print(f\"   R¬≤ Score: {r2:.4f}\")\n",
    "\n",
    "print(\"\\nüíæ SAVED MODEL:\")\n",
    "print(f\"   Filename: best_lstm_model.keras\")\n",
    "print(f\"   Location: Current directory\")\n",
    "\n",
    "print(\"\\n‚úÖ STATUS:\")\n",
    "print(f\"   Training: ‚úì Completed\")\n",
    "print(f\"   Validation: ‚úì Completed\")\n",
    "print(f\"   Testing: ‚úì Completed\")\n",
    "print(f\"   Model Saved: ‚úì Yes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ Model siap untuk digunakan untuk prediksi suhu ruangan!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
